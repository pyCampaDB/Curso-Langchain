{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Componentes de una aplicación RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Document loaders\n",
    "\n",
    "Los `document loaders` (cargadores de docs) son componentes diseñados para facilitar la carga, manipulación y gestión eficiente de docs.\n",
    "\n",
    "LangChain proporciona una serie de `document loaders` integrados para cargar datos de texto desde fuentes comunes como archivos, BBDD y APIs. También es posible crear `document loaders` personalizados para cargar datos de fuentes específicas.\n",
    "\n",
    "## 1.1 - ¿Por qué usarlos?\n",
    "\n",
    "* `Aislamiento de la fuente de datos`: Nos permiten separar las fuentes de datos de la app NLP.\n",
    "* `Flexibilidad`: LangChain posee una larga lista de loaders ya implementados para una gran variedad de fuentes de datos.\n",
    "* `Eficiencia`: Los document loaders pueden optimizarse para cargar datos de texto de forma eficiente.\n",
    "\n",
    "## 1.2 - Tipos\n",
    "\n",
    "* Archivos\n",
    "    - HTML\n",
    "        > `UnstructuredHTMLLoader`\n",
    "        > `WebBaseLoader`\n",
    "    - CSV\n",
    "    - JSON\n",
    "    - PDF\n",
    "* BBDD\n",
    "    - MongoDB\n",
    "    - AWS S3\n",
    "    - Pandas DataFrame\n",
    "* APIs\n",
    "    - Wikipedia\n",
    "    - Twitter (X)\n",
    "    - Telegram\n",
    "    - GitHub\n",
    "\n",
    "\n",
    "## 1.3 - Document loaders personalizados\n",
    "\n",
    "Tb es posible crear document loaders personalizados para cargar datos de fuentes específicas. En este caso, tenemos varias opciones:\n",
    "* Heredar la clase `BaseDocumentLoader`: Es el método general, para diferentes tipos de docs:\n",
    "    \n",
    "    abstract class BaseDocumentLoader implements DocumentLoader {\n",
    "        abstract load(): Promise<Document[]>;    \n",
    "    }\n",
    "* Heredar la clase `TextLoader`: Específico para archivos de texto, pero que tengan un formato específico.\n",
    "    \n",
    "    abstract class TextLoader extends BaseDocumentLoader {\n",
    "        abstract parse(raw:string): Promise<String[]>;\n",
    "    }\n",
    "\n",
    "* Heredar la clase `BufferLoader`: Específico para archivos binarios. La clase `BufferLoader` se encarga de leer el archivo, por lo que todo lo que tenemos que hacer es implementar el método de parseo.\n",
    "\n",
    "    abstract class BufferLoader extends BaseDocumentLoader {\n",
    "        abstract parse(\n",
    "            raw: Buffer,\n",
    "            metadata: Document['metadata']\n",
    "        ): Promise<Document[]>;\n",
    "    }\n",
    "\n",
    "\n",
    "## 1.4 - Ejemplos\n",
    "\n",
    "### 1.4.1 - PyMuPDFLoader\n",
    "\n",
    "pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./assets/\")\n",
    "\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path assets/SA_InteractiveBenefitsChart.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFPlumberLoader\n\u001b[1;32m----> 3\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPDFPlumberLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massets/SA_InteractiveBenefitsChart.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:563\u001b[0m, in \u001b[0;36mPDFPlumberLoader.__init__\u001b[1;34m(self, file_path, text_kwargs, dedupe, headers, extract_images)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdfplumber package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install pdfplumber`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_kwargs \u001b[38;5;241m=\u001b[39m text_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdedupe \u001b[38;5;241m=\u001b[39m dedupe\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:116\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[1;34m(self, file_path, headers)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[1;31mValueError\u001b[0m: File path assets/SA_InteractiveBenefitsChart.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(\"assets/SA_InteractiveBenefitsChart.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\"\"\"\n",
    "    pip install pdf2image\n",
    "    pip install unstructured\n",
    "    pip install pillow_heif\n",
    "    pip install opencv-python\n",
    "    pip install unstructured_inference\n",
    "    pip install pytesseract\n",
    "\"\"\"\n",
    "loader = UnstructuredPDFLoader(\"assets/SA_InteractiveBenefitsChart.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'assets/SA_InteractiveBenefitsChart.pdf'\n",
      "PDF text extraction failed, skip text extraction...\n"
     ]
    },
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\pdf2image\\pdf2image.py:581\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    580\u001b[0m     env[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m poppler_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 581\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:1022\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1020\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1022\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\subprocess.py:1491\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1491\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1493\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pdf_docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(pdf_docs)\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:88\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:73\u001b[0m, in \u001b[0;36mUnstructuredPDFLoader._get_elements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\documents\\elements.py:539\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[1;32m--> 539\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[0;32m    541\u001b[0m     params: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:622\u001b[0m, in \u001b[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Element]:\n\u001b[1;32m--> 622\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[0;32m    624\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\file_utils\\filetype.py:582\u001b[0m, in \u001b[0;36madd_metadata.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Element]:\n\u001b[1;32m--> 582\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[0;32m    584\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\chunking\\dispatch.py:83\u001b[0m, in \u001b[0;36madd_chunking_strategy.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_args\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[0;32m     86\u001b[0m call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults()\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\partition\\pdf.py:217\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[1;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, include_metadata, metadata_filename, metadata_last_modified, chunking_strategy, links, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m exactly_one(filename\u001b[38;5;241m=\u001b[39mfilename, file\u001b[38;5;241m=\u001b[39mfile)\n\u001b[0;32m    215\u001b[0m languages \u001b[38;5;241m=\u001b[39m check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_from_file_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_from_file_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\partition\\pdf.py:329\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[1;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m PartitionStrategy\u001b[38;5;241m.\u001b[39mOCR_ONLY:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# NOTE(robinson): Catches file conversion warnings when running with PDFs\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m--> 329\u001b[0m         elements \u001b[38;5;241m=\u001b[39m \u001b[43m_partition_pdf_or_image_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modification_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m         out_elements \u001b[38;5;241m=\u001b[39m _process_uncategorized_text_elements(elements)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_elements\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\partition\\pdf.py:917\u001b[0m, in \u001b[0;36m_partition_pdf_or_image_with_ocr\u001b[1;34m(filename, file, include_page_breaks, languages, is_image, metadata_last_modified, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m         elements\u001b[38;5;241m.\u001b[39mextend(page_elements)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconvert_pdf_to_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_elements\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_partition_pdf_or_image_with_ocr_from_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43melements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_elements\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\unstructured\\partition\\pdf.py:866\u001b[0m, in \u001b[0;36mconvert_pdf_to_images\u001b[1;34m(filename, file, chunk_size)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m     f_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 866\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mpdf2image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m total_pages \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, total_pages \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, chunk_size):\n",
      "File \u001b[1;32mc:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\pdf2image\\pdf2image.py:607\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m     )\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "pdf_docs = loader.load()\n",
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.2 - `WebBaseLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "web_loader = WebBaseLoader(\"https://github.com/OpenWebinarsNet/Desarrollo-de-Aplicaciones-impulsadas-por-LangChain-en-Python\")\n",
    "web_docs = web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://github.com/OpenWebinarsNet/Desarrollo-de-Aplicaciones-impulsadas-por-LangChain-en-Python',\n",
       " 'title': 'GitHub - OpenWebinarsNet/Desarrollo-de-Aplicaciones-Impulsadas-por-LangChain-en-Python',\n",
       " 'description': 'Contribute to OpenWebinarsNet/Desarrollo-de-Aplicaciones-Impulsadas-por-LangChain-en-Python development by creating an account on GitHub.',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub - OpenWebinarsNet/Desarrollo-de-Aplicaciones-Impulsadas-por-LangChain-en-Python\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Sign in\\n        \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\nPackages\\n        Host and manage packages\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nCodespaces\\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\nCopilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nCode review\\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\nIssues\\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\nDiscussions\\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      All features\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\nFor\\n\\n\\n\\n      Enterprise\\n\\n    \\n\\n\\n\\n      Teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n      Education\\n\\n    \\n\\n\\n\\n\\n\\n\\nBy Solution\\n\\n\\n\\n      CI/CD & Automation\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n\\n\\n\\nResources\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      White papers, Ebooks, Webinars\\n\\n    \\n\\n\\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Sponsors\\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nThe ReadME Project\\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n              Search syntax tips\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n              Sign in\\n            \\n\\n\\n              Sign up\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        OpenWebinarsNet\\n \\n/\\n\\nDesarrollo-de-Aplicaciones-Impulsadas-por-LangChain-en-Python\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n\\n\\n\\n \\n\\nFork\\n    0\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 0\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0\\n          stars\\n \\n\\n\\n\\n0\\n          forks\\n \\n\\n\\n\\nBranches\\n \\n\\n\\n\\nTags\\n \\n\\n\\n\\nActivity\\n \\n\\n\\n\\n \\n\\n\\n          Star\\n\\n  \\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n0\\n\\n\\n\\n\\n\\n\\nPull requests\\n0\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nOpenWebinarsNet/Desarrollo-de-Aplicaciones-Impulsadas-por-LangChain-en-Python\\n\\n\\n\\n\\n\\n\\n\\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History1 CommitsSección 3 - Componentes fundamentales de LangChainSección 3 - Componentes fundamentales de LangChain\\xa0\\xa0Sección 4 - Retrieval Augmented Generation con LangChain/Lección 2 - Componentes LangChain para una aplicación RAGSección 4 - Retrieval Augmented Generation con LangChain/Lección 2 - Componentes LangChain para una aplicación RAG\\xa0\\xa0Sección 5 - ProyectoSección 5 - Proyecto\\xa0\\xa0View all files   \\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n        No description, website, or topics provided.\\n      \\n\\n\\n\\n\\n\\n\\n\\nActivity\\n \\n\\n\\n\\n\\n\\nCustom properties\\n \\nStars\\n\\n\\n\\n\\n\\n0\\n      stars\\n \\nWatchers\\n\\n\\n\\n\\n\\n2\\n      watching\\n \\nForks\\n\\n\\n\\n\\n\\n0\\n      forks\\n \\n\\n\\n          Report repository\\n \\n\\n\\n\\n\\n\\n\\n\\n    Releases\\n\\nNo releases published\\n\\n\\n\\n\\n\\n\\n    Packages\\n      0\\n\\n\\n        No packages published \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLanguages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJupyter Notebook\\n100.0%\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2024 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n      Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can’t perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien este loader es capaz de extraer el texto directamente a partir de una pág HTML con una sola línea de código, el texto resultante puede requerir limpieza antes de ser utilizado para entrenar o para inferencia con un LLM\n",
    "\n",
    "P. ej., en este caso como mínimo deberíamos limpiar el número de saltos de página\n",
    "\n",
    "\n",
    "## 1.4.3 - WikipediaLoader\n",
    "\n",
    "pip install wikipedia\n",
    "En este caso, le hacemos una query a wikipedia (como si usáramos la parte \"búsqueda\" en la web) y recuperamos como máx los dos primeros docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "wiki_docs = WikipediaLoader(query=\"Naruto Shippuden\", load_max_docs=2).load()\n",
    "\n",
    "len(wiki_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Naruto (TV series)',\n",
       " 'summary': \"Naruto is a Japanese anime television series based on Masashi Kishimoto's manga series of the same name. The story follows Naruto Uzumaki, a young ninja who seeks recognition from his peers and dreams of becoming the Hokage, the leader of his village. Just like the manga, the anime series is divided into two separate parts: the first series retains the original manga's title and is set in Naruto's pre-teen years. The second series, a direct sequel titled Naruto: Shippuden, takes place during his teens. Both anime series were animated by Pierrot, produced by Aniplex and licensed in North America by Viz Media.\\nThe first anime series aired on TV Tokyo and ran for 220 episodes from October 2002 to February 2007; an English dub produced by Viz Media aired on Cartoon Network and YTV from September 2005 to December 2009. The second series, Shippuden, also aired on TV Tokyo and ran for 500 episodes from February 2007 to March 2017. The English dub of Shippuden was broadcast on Disney XD in the United States from October 2009 to November 2011, airing the first 98 episodes before eventually switching over to Adult Swim's Toonami programming block in January 2014, starting over from the first episode. After Disney XD removed the series from broadcast, Viz Media began streaming new English dubbed episodes on their streaming service Neon Alley in December 2012 starting at episode 99. The service aborted its run in March 2016 after 338 episodes due to its shutdown a month later. Besides the anime television series, Pierrot also developed 11 animated films and 12 original video animations (OVAs).\",\n",
       " 'source': 'https://en.wikipedia.org/wiki/Naruto_(TV_series)'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'List of Naruto: Shippuden episodes',\n",
       " 'summary': \"Naruto: Shippuden is an anime television series mainly adapted from Part II of Masashi Kishimoto's original Naruto manga series, with exactly 500 episodes. It is set two and a half years after the original series in the Naruto universe, following the teenage ninja Naruto Uzumaki and his allies. The series is directed by Hayato Date, and produced by Pierrot and TV Tokyo. It began broadcasting on February 15, 2007, on TV Tokyo, and concluded on March 23, 2017.On January 2, 2009, Viz Media and Crunchyroll provided eight English subtitled Naruto: Shippuden episodes on the official Naruto website. Later the following 2 weeks, Viz began providing subtitled versions of the latest Naruto: Shippuden episodes a week after they first aired in Japan, with a new episode being added to the Naruto website each subsequent Thursday. On July 24, 2009, Viz Media announced that the series would be released on the iTunes Store. The first DVD release of the series in North America was released on September 29, 2009. The English dub of Naruto: Shippuden made its US premiere on Disney XD on October 28, 2009.Naruto: Shippuden stopped airing on Disney XD on November 5, 2011 after 98 episodes. The English dub was streamed on the Neon Alley web channel from its launch in October 2012, and beginning December 29 of the same year with episode 99, dubbed episodes premiered every week until March 25, 2016 after 338 episodes, about a month before Neon Alley's closure. Adult Swim's Toonami programming block began airing the anime from the beginning on January 5, 2014 in an uncut format. The network started showing never before aired dubbed episodes at the 339th episode mark by May 2021.In four regions, episodes from the series have been released on DVD and Blu-ray by single volumes and box sets. In Japan, twenty six sets of volumes have been released based on which arc it represents. In North America, twelve single volumes and thirty eight box sets have been released. In the United Kingdom, twenty eight single volumes and six box sets have been released. In Australia and New Zealand, twenty-eight collections have been released.\",\n",
       " 'source': 'https://en.wikipedia.org/wiki/List_of_Naruto:_Shippuden_episodes'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Naruto is a Japanese anime television series based on Masashi Kishimoto's manga series of the same name. The story follows Naruto Uzumaki, a young ninja who seeks recognition from his peers and dreams of becoming the Hokage, the leader of his village. Just like the manga, the anime series is divided into two separate parts: the first series retains the original manga's title and is set in Naruto's pre-teen years. The second series, a direct sequel titled Naruto: Shippuden, takes place during his teens. Both anime series were animated by Pierrot, produced by Aniplex and licensed in North America by Viz Media.\\nThe first anime series aired on TV Tokyo and ran for 220 episodes from October 2002 to February 2007; an English dub produced by Viz Media aired on Cartoon Network and YTV from September 2005 to December 2009. The second series, Shippuden, also aired on TV Tokyo and ran for 500 episodes from February 2007 to March 2017. The English dub of Shippuden was broadcast on Disney XD in the United States from October 2009 to November 2011, airing the first 98 episodes before eventually switching over to Adult Swim's Toonami programming block in January 2014, starting over from the first episode. After Disney XD removed the series from broadcast, Viz Media began streaming new English dubbed episodes on their streaming service Neon Alley in December 2012 starting at episode 99. The service aborted its run in March 2016 after 338 episodes due to its shutdown a month later. Besides the anime television series, Pierrot also developed 11 animated films and 12 original video animations (OVAs).\\n\\n\\n== Voice cast and characters ==\\n\\n\\n== Production and release ==\\n\\n\\n=== Part I (2002–07) ===\\nThe first Naruto anime series, directed by Hayato Date and produced by Studio Pierrot and TV Tokyo, premiered in Japan on October 3, 2002, and concluded on February 8, 2007, after 220 episodes. The first 135 episodes were adapted from Part I of the manga; the remaining 85 episodes are original and use plot elements that are not in the manga. Tetsuya Nishio was the character designer for Naruto when the manga was adapted into an anime series; Kishimoto had requested that Nishio be given this role. Beginning on April 29, 2009, the original Naruto anime began a rerun on Wednesdays and Thursdays (until the fourth week of September 2009 when it changed to only Wednesdays). It was remastered in HD, with new 2D and 3D effects, under the name  Naruto: Shōnen Hen.  Episodes from the series have been released on both VHS and DVD, and collected as boxed sets.Viz licensed the anime series for broadcast and distribution in the Region 1 market. The English dub of the anime began airing on September 10, 2005, and concluded on January 31, 2009, with 209 episodes aired on Cartoon Network's Toonami in the United States. The episodes were also broadcast on YTV's Bionix (Canada), Jetix (United Kingdom) and SABC 2's (South Africa) programming blocks, and were released on DVD on March 28, 2006. On August 25, 2017, Starz announced that they would be offering episodes of the series for their Video on Demand service starting September 1, 2017. The first 26 volumes contain four episodes; later DVD volumes have five episodes. Uncut editions were released in DVD box sets, each containing 12–15 episodes, with some variation based on story arcs. In the American broadcast, references to alcohol, Japanese culture, sexual innuendo, and the appearance of blood and death were sometimes edited but remained in the DVD editions. One of the censored scenes was the accidental kiss between Naruto and Sasuke, fitting in the long trend of removing content that alludes to homosexual relationships. The series was also licensed to Hulu, Joost, and Crunchyroll, which aired the episodes online with the original Japanese audio tracks and English subtitles.  On June 1, 2017, it was announced that an HD remaster version of the original Naruto television anime series would debut on Japanese TV on June 24, star\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Naruto: Shippuden is an anime television series mainly adapted from Part II of Masashi Kishimoto\\'s original Naruto manga series, with exactly 500 episodes. It is set two and a half years after the original series in the Naruto universe, following the teenage ninja Naruto Uzumaki and his allies. The series is directed by Hayato Date, and produced by Pierrot and TV Tokyo. It began broadcasting on February 15, 2007, on TV Tokyo, and concluded on March 23, 2017.On January 2, 2009, Viz Media and Crunchyroll provided eight English subtitled Naruto: Shippuden episodes on the official Naruto website. Later the following 2 weeks, Viz began providing subtitled versions of the latest Naruto: Shippuden episodes a week after they first aired in Japan, with a new episode being added to the Naruto website each subsequent Thursday. On July 24, 2009, Viz Media announced that the series would be released on the iTunes Store. The first DVD release of the series in North America was released on September 29, 2009. The English dub of Naruto: Shippuden made its US premiere on Disney XD on October 28, 2009.Naruto: Shippuden stopped airing on Disney XD on November 5, 2011 after 98 episodes. The English dub was streamed on the Neon Alley web channel from its launch in October 2012, and beginning December 29 of the same year with episode 99, dubbed episodes premiered every week until March 25, 2016 after 338 episodes, about a month before Neon Alley\\'s closure. Adult Swim\\'s Toonami programming block began airing the anime from the beginning on January 5, 2014 in an uncut format. The network started showing never before aired dubbed episodes at the 339th episode mark by May 2021.In four regions, episodes from the series have been released on DVD and Blu-ray by single volumes and box sets. In Japan, twenty six sets of volumes have been released based on which arc it represents. In North America, twelve single volumes and thirty eight box sets have been released. In the United Kingdom, twenty eight single volumes and six box sets have been released. In Australia and New Zealand, twenty-eight collections have been released.\\n\\n\\n== Series overview ==\\n\\n\\n== Episodes ==\\n\\n\\n=== Season 1 (2007) ===\\n\\n\\n=== Season 2 (2007–08) ===\\n\\n\\n=== Season 3 (2008) ===\\n\\n\\n=== Season 4 (2008) ===\\n\\n\\n=== Season 5 (2008–09) ===\\n\\n\\n=== Season 6 (2009–10) ===\\n\\n\\n=== Season 7 (2010) ===\\n\\n\\n=== Season 8 (2010) ===\\n\\n\\n=== Season 9 (2010–11) ===\\n\\n\\n=== Season 10 (2011) ===\\n\\n\\n=== Season 11 (2011) ===\\n\\n\\n=== Season 12 (2012) ===\\n\\n\\n=== Season 13 (2012–13) ===\\n\\n\\n=== Season 14 (2013) ===\\n\\n\\n=== Season 15 (2013–14) ===\\n\\n\\n=== Season 16 (2014) ===\\n\\n\\n=== Season 17 (2014) ===\\n\\n\\n=== Season 18 (2014) ===\\n\\n\\n=== Season 19 (2015) ===\\n\\n\\n=== Season 20 (2015–16) ===\\n\\n\\n=== Season 21 (2016) ===\\n\\n\\n=== Season 22 (2016–17) ===\\n\\n\\n== Home media release ==\\n\\n\\n=== DVD ===\\n\\n\\n=== Region 1 (North America) ===\\n\\n\\n==== Single volumes ====\\n\\n\\n==== Box sets ====\\n\\n\\n==== Blu-ray Sets ====\\n\\n\\n=== Region 2 (UK) ===\\n\\n\\n==== Box sets ====\\n\\n\\n==== Series sets ====\\n\\n\\n=== Region 3 (Japan) ===\\n\\n\\n=== Region 4 (Australia/NZ) ===\\n\\n\\n==== Hokage Box Sets ====\\n\\n\\n==== Chakra Collection ====\\n\\n\\n=== Blu-ray ===\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n=== Bibliography ===\\n\"Naruto: Shippuden episodes from 2007\" (in Japanese). TV Tokyo. Archived from the original on December 16, 2009.\\n\"Naruto: Shippuden episodes from 2008\" (in Japanese). TV Tokyo. Archived from the original on December 31, 2009.\\n\"Naruto: Shippuden episodes from 2009\" (in Japanese). TV Tokyo. Archived from the original on December 31, 2010.\\n\"Naruto: Shippuden episodes from 2010\" (in Japanese). TV Tokyo. Archived from the original on December 31, 2010.\\n\"Naruto: Shippuden episodes from 2011\" (in Japanese). TV Tokyo. Archived from the original on April 19, 2007.\\nNARUTO疾風伝. Media Arts Database (in Japanese). Agency for Cultural Affairs. Archived from the original on October 1, 2016.\\n\"List of Naruto: Shippuden episode titles\". Archived from the original on December 19, 2009.\\n\"Naruto: Shippuden\". Toonzone. '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_docs[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Text splitter\n",
    "\n",
    "Los `text splitters` (separadores de texto) son componentes diseñados para dividir los textos cargados en trozos que quepan en la ventana de contexto de un modelo de embeddings o un LLM\n",
    "\n",
    "LangChain proporciona varios text splitters para texto general, HTML y código.\n",
    "\n",
    "## 2.1 - ¿Por qué utilizarlos?\n",
    "\n",
    "A primera vista, la idea de dividir el texto en trozos pequeños puede parecer simple. Sin embargo, hay mucho potencial de complejidad, ya que, por lo general, queremos mantener juntos los trozos de texto que se encuentren relacionados semánticamente. Lo que significa \"relacionado semánticamente\" podría depender del tipo de texto (no es lo mismo el texto de una novela que el de un código Python).\n",
    "\n",
    "Distinguimos dos características principales en un `text splitter` (separador de texto):\n",
    "* Cómo se divide el texto\n",
    "* Cómo se mide el tamaño de trozo\n",
    "\n",
    "## 2.2 - Tipos\n",
    "* `RecursiveCharacterTextSplitter`\n",
    "* `HTMLHeaderTextSplitter`\n",
    "* `MarkdownHeaderTextSplitter`\n",
    "* `Código`\n",
    "* `Token`\n",
    "* `CharacterTextSplitter`\n",
    "\n",
    "## 2.3 - Ejemplos\n",
    "\n",
    "### 2.3.1 - `RecursiveCharacterTextSplitter`\n",
    "\n",
    "Este separador dev texto es el más recomendado para texto genérico. Intenta dividir el texto en orden hasta que los trozos sean lo suficientemente pequeños.\n",
    "\n",
    "Está parametrizado por una lista de caracteres. La lista predeterminada es `[\\n\\n, \\n, \" \", \"\"]`. Esto tiene el efecto de intentar mantener todos los párrafos (y luego las oraciones, y luego las palabras) juntos tanto como sea posible, ya que esos serían genéricamente los trozos de texto semánticamente más relacionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naruto is a Japanese anime television series based on Masashi Kishimoto's manga series of the same name. The story follows Naruto Uzumaki, a young ninja who seeks recognition from his peers and dreams of becoming the Hokage, the leader of his village. Just like the manga, the anime series is divided into two separate parts: the first series retains the original manga's title and is set in Naruto's pre-teen years. The second series, a direct sequel titled Naruto: Shippuden, takes place during his teens. Both anime series were animated by Pierrot, produced by Aniplex and licensed in North America by Viz Media.\n",
      "The first anime series aired on TV Tokyo and ran for 220 episodes from October 2002 to February 2007; an English dub produced by Viz Media aired on Cartoon Network and YTV from September 2005 to December 2009. The second series, Shippuden, also aired on TV Tokyo and ran for 500 episodes from February 2007 to March 2017. The English dub of Shippuden was broadcast on Disney XD in the United States from October 2009 to November 2011, airing the first 98 episodes before eventually switching over to Adult Swim's Toonami programming block in January 2014, starting over from the first episode. After Disney XD removed the series from broadcast, Viz Media began streaming new English dubbed episodes on their streaming service Neon Alley in December 2012 starting at episode 99. The service aborted its run in March 2016 after 338 episodes due to its shutdown a month later. Besides the anime television series, Pierrot also developed 11 animated films and 12 original video animations (OVAs).\n",
      "\n",
      "\n",
      "== Voice cast and characters ==\n",
      "\n",
      "\n",
      "== Production and release ==\n",
      "\n",
      "\n",
      "=== Part I (2002–07) ===\n",
      "The first Naruto anime series, directed by Hayato Date and produced by Studio Pierrot and TV Tokyo, premiered in Japan on October 3, 2002, and concluded on February 8, 2007, after 220 episodes. The first 135 episodes were adapted from Part I of the manga; the remaining 85 episodes are original and use plot elements that are not in the manga. Tetsuya Nishio was the character designer for Naruto when the manga was adapted into an anime series; Kishimoto had requested that Nishio be given this role. Beginning on April 29, 2009, the original Naruto anime began a rerun on Wednesdays and Thursdays (until the fourth week of September 2009 when it changed to only Wednesdays). It was remastered in HD, with new 2D and 3D effects, under the name  Naruto: Shōnen Hen.  Episodes from the series have been released on both VHS and DVD, and collected as boxed sets.Viz licensed the anime series for broadcast and distribution in the Region 1 market. The English dub of the anime began airing on September 10, 2005, and concluded on January 31, 2009, with 209 episodes aired on Cartoon Network's Toonami in the United States. The episodes were also broadcast on YTV's Bionix (Canada), Jetix (United Kingdom) and SABC 2's (South Africa) programming blocks, and were released on DVD on March 28, 2006. On August 25, 2017, Starz announced that they would be offering episodes of the series for their Video on Demand service starting September 1, 2017. The first 26 volumes contain four episodes; later DVD volumes have five episodes. Uncut editions were released in DVD box sets, each containing 12–15 episodes, with some variation based on story arcs. In the American broadcast, references to alcohol, Japanese culture, sexual innuendo, and the appearance of blood and death were sometimes edited but remained in the DVD editions. One of the censored scenes was the accidental kiss between Naruto and Sasuke, fitting in the long trend of removing content that alludes to homosexual relationships. The series was also licensed to Hulu, Joost, and Crunchyroll, which aired the episodes online with the original Japanese audio tracks and English subtitles.  On June 1, 2017, it was announced that an HD remaster version of the original Naruto television anime series would debut on Japanese TV on June 24, star\n"
     ]
    }
   ],
   "source": [
    "text = wiki_docs[0].page_content\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Ponemos un chunk size muy pequeño, simplemente para mostrar la funcionalidad\n",
    "    chunk_size = 100, #caracteres máximos\n",
    "    chunk_overlap = 20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #0\n",
      "\n",
      "Naruto is a Japanese anime television series based on Masashi Kishimoto's manga series of the same\n",
      "\n",
      "\n",
      "Chunk #1\n",
      "\n",
      "series of the same name. The story follows Naruto Uzumaki, a young ninja who seeks recognition from\n",
      "\n",
      "\n",
      "Chunk #2\n",
      "\n",
      "recognition from his peers and dreams of becoming the Hokage, the leader of his village. Just like\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = recursive_text_splitter.split_text(text)\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(f'Chunk #{i}\\n')\n",
    "    print(chunks[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 - Dividir por tokens usando `tiktoken`\n",
    "\n",
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "tiktoken_text_splitter = TokenTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #0\n",
      "\n",
      "Naruto is a Japanese anime television series based on Masashi Kishimoto's manga series of the same name. The story follows Naruto Uzumaki, a young ninja who seeks recognition from his peers and dreams of becoming the Hokage, the leader of his village. Just like the manga, the anime series is divided into two separate parts: the first series retains the original manga's title and is set in Naruto's pre-teen years. The second series, a direct sequel titled Naruto: Sh\n",
      "\n",
      "\n",
      "Chunk #1\n",
      "\n",
      "ippuden, takes place during his teens. Both anime series were animated by Pierrot, produced by Aniplex and licensed in North America by Viz Media.\n",
      "The first anime series aired on TV Tokyo and ran for 220 episodes from October 2002 to February 2007; an English dub produced by Viz Media aired on Cartoon Network and YTV from September 2005 to December 2009. The second series, Shippuden, also aired on TV Tokyo and ran for 500 episodes from February 2007 to March 2017. The\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = tiktoken_text_splitter.split_text(text)\n",
    "\n",
    "for i in range(0,2):\n",
    "    print(f'Chunk #{i}\\n')\n",
    "    print(chunks[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3 - Dividir código\n",
    "\n",
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def hello_world():\\n    print(\"hello world!\")'),\n",
       " Document(page_content='# LLama a la función\\nhello_world()')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter\n",
    ")\n",
    "\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"hello world!\")\n",
    "    \n",
    "# LLama a la función\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='🤔 What is LangChain?'),\n",
       " Document(page_content='LangChain is a framework for developing applications'),\n",
       " Document(page_content='powered by large language models (LLMs).'),\n",
       " Document(page_content='For these applications, LangChain simplifies the entire'),\n",
       " Document(page_content='application lifecycle:'),\n",
       " Document(page_content='Open-source libraries: Build your applications using'),\n",
       " Document(page_content=\"LangChain's modular building blocks and components.\"),\n",
       " Document(page_content='Integrate with hundreds of third-party providers.'),\n",
       " Document(page_content='Productionization: Inspect, monitor, and evaluate your apps'),\n",
       " Document(page_content='with LangSmith so that you can constantly optimize and'),\n",
       " Document(page_content='deploy with confidence.'),\n",
       " Document(page_content='Deployment: Turn any chain into a REST API with LangServe.'),\n",
       " Document(page_content='Open-source libraries'),\n",
       " Document(page_content='langchain-core: Base abstractions and LangChain Expression'),\n",
       " Document(page_content='Language.'),\n",
       " Document(page_content='langchain-community: Third party integrations.'),\n",
       " Document(page_content='Some integrations have been further split into partner'),\n",
       " Document(page_content='packages that only rely on langchain-core. Examples include'),\n",
       " Document(page_content='langchain_openai and langchain_anthropic.'),\n",
       " Document(page_content='langchain: Chains, agents, and retrieval strategies that'),\n",
       " Document(page_content=\"make up an application's cognitive architecture.\"),\n",
       " Document(page_content='[LangGraph](https://python.langchain.com/docs/langgraph): A'),\n",
       " Document(page_content='library for building robust and stateful multi-actor'),\n",
       " Document(page_content='applications with LLMs by modeling steps as edges and nodes'),\n",
       " Document(page_content='in a graph.'),\n",
       " Document(page_content='Productionization:'),\n",
       " Document(page_content='LangSmith: A developer platform that lets you debug, test,'),\n",
       " Document(page_content='evaluate, and monitor chains built on any LLM framework and'),\n",
       " Document(page_content='seamlessly integrates with LangChain.'),\n",
       " Document(page_content='Deployment:'),\n",
       " Document(page_content='LangServe: A library for deploying LangChain chains as REST'),\n",
       " Document(page_content='APIs.')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "🤔 What is LangChain?\n",
    "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
    "\n",
    "For these applications, LangChain simplifies the entire application lifecycle:\n",
    "\n",
    "Open-source libraries: Build your applications using LangChain's modular building blocks and components. Integrate with hundreds of third-party providers.\n",
    "Productionization: Inspect, monitor, and evaluate your apps with LangSmith so that you can constantly optimize and deploy with confidence.\n",
    "Deployment: Turn any chain into a REST API with LangServe.\n",
    "Open-source libraries\n",
    "langchain-core: Base abstractions and LangChain Expression Language.\n",
    "langchain-community: Third party integrations.\n",
    "Some integrations have been further split into partner packages that only rely on langchain-core. Examples include langchain_openai and langchain_anthropic.\n",
    "langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.\n",
    "[LangGraph](https://python.langchain.com/docs/langgraph): A library for building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\n",
    "Productionization:\n",
    "LangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.\n",
    "Deployment:\n",
    "LangServe: A library for deploying LangChain chains as REST APIs.\"\"\"\n",
    "\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, \n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "md_docs = md_splitter.create_documents([markdown_text])\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Modelo de embeddings\n",
    "\n",
    "La clase Embeddings es una clase diseñada para interactuar con modelos de embeddings de texto. Hay muchos proveedores de modelos de embedding (OpenAI, Cohere, Hugging Face, etc) - esta clase está diseñada para proporcionar una interfaz estándar para todos ellos.\n",
    "\n",
    "La clase base Embeddings en LangChain proporciona dos métodos:\n",
    "* `embed_documents`: Método para convertir docs. Toma como entrada varios docs.\n",
    "* `embed_query`: Método para convertir una consulta. Toma como entrada un texto.\n",
    "\n",
    "La razón para tener dos métodos separados es que algunos modelos de embedding ofrecen funcionalidad distinta cuando el input es un solo texto o varios docs.\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 - OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "#from langchain_openai import OpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "openai_embeddings_model = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-large\",\n",
    "    openai_api_key = getenv('OPEN_API_KEY', '')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "[0.008390028175443806, 0.010463886144756681, 0.007829723084401498, 0.021000538386177416, 0.018439142353808877]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hola Mundo\"\n",
    "embedded_query = openai_embeddings_model.embed_query(text)\n",
    "\n",
    "print(len(embedded_query)) #nº de dimensiones de embeddings resultante\n",
    "print(embedded_query[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3072\n",
      "[0.008404222021682468, 0.010419780022282311, 0.007865769512188701, 0.020999639488354007, 0.018394694948444697]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hola Mundo\"\n",
    "text2 = \"Hello World\"\n",
    "\n",
    "texts = [text1, text2]\n",
    "embedded_docs = openai_embeddings_model.embed_documents(texts)\n",
    "print(len(embedded_docs)) # numero de vectores devueltos\n",
    "print(len(embedded_docs[0])) # dimensionalidad de embeddings resultante\n",
    "print(embedded_docs[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - HuggingFace\n",
    "\n",
    "### 3.4.2 - API\n",
    "\n",
    "Podemos correr los modelos de forma remota mediante la API abierta de HuggingFace (aunque para temas serios tendríamos que pagar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "huggingface_embeddings_model = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key = getenv(\"API_HUGGING\", \"\")\n",
    "    model_name = \"sentence-transformers/all-MiniLM-16-v2\"\n",
    "\n",
    "    embedded_query = huggingface_embeddings_model.embedded_query(text)\n",
    "    print(len(embedded_query)) # núm de dim\n",
    "    print(embedded_query[:5])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 - Local\n",
    "\n",
    "También podemos correr el modelo de embeddings de forma local (debería salir el mismo resultado)\n",
    "\n",
    "`pip install sentence_transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\rafacampa9\\.virtualenvs\\Langchain-NIv1GH6l\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rafacampa9\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "[-0.04199906066060066, 0.13960984349250793, 0.007648400496691465, -0.008638311177492142, -0.030084870755672455]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "local_huggingface_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "embedded_query = local_huggingface_embeddings_model.embed_query(text)\n",
    "print(len(embedded_query))\n",
    "print(embedded_query[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Base de datos vectorial\n",
    "\n",
    "Hay una gran cantidad de bases de datos vectoriales. Aquí vamos a mostrar la funcionalidad con Chroma, una alternativa open source que además no necesita de una API ya que funcionan de forma local (perfecto para hacer pruebas)\n",
    "\n",
    "Para explorar todas las posibilidades que ofrece LangChain, lo mejor es acudir a la doc.\n",
    "\n",
    "`pip install chromadb`\n",
    "\n",
    "\n",
    "## 4.1 - Ejemplo con Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemos cargado 20 chunks de texto\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "tiktoken_text_splitter = TokenTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = tiktoken_text_splitter.split_documents(wiki_docs)\n",
    "\n",
    "print(f'Hemos cargado {len(chunks)} chunks de texto')\n",
    "\n",
    "#Cargamos y aplicamos el modelo de embedings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "#Guardamos los chunks en una instancia de Chroma que reside en memoria RAM\n",
    "db = Chroma.from_documents(chunks, embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos generado la db con los chunks de texto relevantes, podemos hacer querys sobre ella de dos formas:\n",
    "* `db.similarity_search()`: Directamente con el texto en cuestión (LangChain llama auto al modelo y genera el vector de embeddings)\n",
    "* `db-similarity_search_by_vector()`: Con el vector de embeddings (habiéndolo generado manualmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " December 19, 2009.\n",
      "\"Naruto: Shippuden\". Toonzone. \n"
     ]
    }
   ],
   "source": [
    "# prueba con el texto directamente\n",
    "query = \"when is Naruto from?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " December 19, 2009.\n",
      "\"Naruto: Shippuden\". Toonzone. \n"
     ]
    }
   ],
   "source": [
    "query = \"when is Naruto from\"\n",
    "query_embedding_vector = embeddings_model.embed_query(query)\n",
    "docs = db.similarity_search_by_vector(query_embedding_vector)\n",
    "\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siguiente\n",
    "\n",
    "En la siguiente lección, veremos aspectos con los que extender la funcionalidad de nuestro sistema RAG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain-NIv1GH6l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
